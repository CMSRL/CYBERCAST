{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddd88a3-ced8-426c-afbc-9e6bd6b90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4e158-a39b-4f21-bf6d-102673929080",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file = ''\n",
    "output_csv_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ce6c4-7289-4002-ace4-b812c3b385db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_csv(input_json_file, output_csv_file):\n",
    "    try:\n",
    "        # Open input file\n",
    "        with open(input_json_file, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        # Open output CSV in write mode\n",
    "        with open(output_csv_file, 'w', newline='') as csv_file:\n",
    "            # Let's define our CSV writer and column headers\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([\n",
    "                'Timestamp', 'IP Address', 'Device Name', 'Device ID', 'Device Owner', 'Device Owner ID', 'Force Identifier',\n",
    "                'Latitude', 'Longitude', 'Elevation', \n",
    "                'Hacked', 'Denial of Service Attacked', 'Delay Attacked',\n",
    "                'Interception Attacked', 'Repaired', 'Packet Degradation',\n",
    "                'Discovered', 'Kernel Panicked', 'Disrupted', 'Outbound Network Traffic',\n",
    "                'Inbound Network Traffic', 'Exploited', 'Injection Attacked', 'Disabled',\n",
    "                'Powered On', 'CPU Utilization', 'Device Removed', 'Disk Utilization',\n",
    "                'EffectType', 'TargetDevice', 'InitiatingDevice', 'InitiatingName', 'EffectStatus'\n",
    "            ])\n",
    "\n",
    "            # Need helper function to normalize case \n",
    "            # Ex. Some logs have \"Denial of Service Attack\" while others are \"denial of service attack\"\n",
    "            def get_normalized_value(data_dict, key, default='N/A'):\n",
    "                # update to all lowercase\n",
    "                normalized_data = {k.lower(): v for k, v in data_dict.items()}\n",
    "                return normalized_data.get(key.lower(), default)\n",
    "\n",
    "            # Start iterating through data\n",
    "            for entry in data:\n",
    "                try:\n",
    "                    # Check if 'data' exists in the log\n",
    "                    if 'data' in entry and 'log' in entry['data']:\n",
    "                        log_data = entry['data']['log']\n",
    "\n",
    "                        # Focus on logs with'Message Received'\n",
    "                        # Extract important data and normalize case for lookups\n",
    "                        if \"Message Received\" in log_data:\n",
    "                            try:\n",
    "                                parsed_log = json.loads(log_data.split(\"Message Received\")[1].strip())\n",
    "\n",
    "                                # General\n",
    "                                timestamp = entry['data'].get('time', 'N/A')\n",
    "                                ip_address = get_normalized_value(parsed_log, 'interfaceIPAddress', 'N/A')\n",
    "                                name = get_normalized_value(parsed_log, 'deviceName', 'N/A')\n",
    "                                device_id = get_normalized_value(parsed_log, 'deviceID', 'N/A')\n",
    "                                owner_name = get_normalized_value(parsed_log, 'entityName', 'N/A')\n",
    "                                owner_id = get_normalized_value(parsed_log, 'owningEntityID', 'N/A')\n",
    "                                force = get_normalized_value(parsed_log, 'deviceForceIdentifier', 'N/A')\n",
    "\n",
    "                                # Latitude, Longitude, Elevation\n",
    "                                latitude = get_normalized_value(parsed_log, 'latitude', 'N/A')\n",
    "                                longitude = get_normalized_value(parsed_log, 'longitude', 'N/A')\n",
    "                                elevation = get_normalized_value(parsed_log, 'elevation', 'N/A')\n",
    "\n",
    "                                # Attack Status\n",
    "                                hacked = get_normalized_value(parsed_log, 'hacked', 'False')\n",
    "                                dos_attacked = get_normalized_value(parsed_log, 'Denial of Service Attacked', 'False')\n",
    "                                delay_attacked = get_normalized_value(parsed_log, 'Delay Attacked', 'False')\n",
    "                                interception_attacked = get_normalized_value(parsed_log, 'Interception Attacked', 'False')\n",
    "                                injection_attacked = get_normalized_value(parsed_log, 'Injection Attacked', 'False')\n",
    "\n",
    "                                # Network Information\n",
    "                                outbound_traffic = get_normalized_value(parsed_log, 'Outbound Network Traffic', 'N/A')\n",
    "                                inbound_traffic = get_normalized_value(parsed_log, 'Inbound Network Traffic', 'N/A')\n",
    "                                packet_degradation = get_normalized_value(parsed_log, 'Packet Degradation', 'False')\n",
    "\n",
    "                                # Status Information\n",
    "                                exploited = get_normalized_value(parsed_log, 'Exploited', 'False')\n",
    "                                repaired = get_normalized_value(parsed_log, 'repaired', 'False')\n",
    "                                discovered = get_normalized_value(parsed_log, 'Discovered', 'False')\n",
    "                                kernel_panicked = get_normalized_value(parsed_log, 'Kernel Panicked', 'False')\n",
    "                                disrupted = get_normalized_value(parsed_log, 'Disrupted', 'False')\n",
    "                                disabled = get_normalized_value(parsed_log, 'Disabled', 'False')\n",
    "                                powered_on = get_normalized_value(parsed_log, 'Powered On', 'False')\n",
    "\n",
    "                                # Device Resources\n",
    "                                cpu_utilization = get_normalized_value(parsed_log, 'CPU Utilization', 'N/A')\n",
    "                                device_removed = get_normalized_value(parsed_log, 'Device Removed', 'False')\n",
    "                                disk_utilization = get_normalized_value(parsed_log, 'Disk Utilization', 'N/A')\n",
    "\n",
    "                                # Cyber Effects\n",
    "                                effect_type = get_normalized_value(parsed_log, 'effect type', 'N/A')\n",
    "                                target_device = get_normalized_value(parsed_log, 'targets', 'N/A')\n",
    "                                initiating_device = get_normalized_value(parsed_log, 'initiating device id', 'N/A')\n",
    "                                initiating_name = get_normalized_value(parsed_log, 'initiatingName', 'N/A')\n",
    "                                effect_status = get_normalized_value(parsed_log, 'cyber effect status', 'N/A')\n",
    "\n",
    "                                # Write to CSV\n",
    "                                csv_writer.writerow([\n",
    "                                    timestamp, ip_address, name, device_id, owner_name, owner_id, force,\n",
    "                                    latitude, longitude, elevation,\n",
    "                                    hacked, dos_attacked, delay_attacked, interception_attacked,\n",
    "                                    repaired, packet_degradation, discovered, kernel_panicked,\n",
    "                                    disrupted, outbound_traffic, inbound_traffic, exploited, injection_attacked,\n",
    "                                    disabled, powered_on, cpu_utilization, device_removed, disk_utilization,\n",
    "                                    effect_type, target_device, initiating_device, initiating_name, effect_status\n",
    "                                ])\n",
    "# -- general error handling --\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Skipping entry due to JSON decode error: {e}\")\n",
    "                        else:\n",
    "                            print(\"Skipping entry: 'Message Received' not found in log.\")\n",
    "                            continue\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Skip the entry if any error occurs while processing\n",
    "                    print(f\"Skipping invalid entry due to error: {e}\")\n",
    "                    continue  \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e794c1-b841-4764-b96b-77a8412000ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parse_json_to_csv(input_json_file, output_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186b20c-45ca-4d15-b85e-e2adaee3d0e2",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc1090-d891-44f6-aea8-6260c4cd7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reads a CSV file, extracts timestamps, converts them into milliseconds and ensures they fall within the range 0 - 380,436 ms by normalizing them\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp_to_ms(timestamp, min_time, max_time):\n",
    "    try:\n",
    "        trimmed_timestamp = timestamp.split('Z')[0][:26]  # Ensure at most 6 decimal places\n",
    "        dt = datetime.strptime(trimmed_timestamp, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        ms_value = int(dt.timestamp() * 1000)\n",
    "        return normalize_timestamp(ms_value, min_time, max_time)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing timestamp: {timestamp}\")\n",
    "        return None\n",
    "\n",
    "def normalize_timestamp(ms_value, min_time, max_time):\n",
    "    return int((ms_value - min_time) / (max_time - min_time) * 380436)\n",
    "\n",
    "def update_csv_timestamps(input_file, output_file):\n",
    "    df = pd.read_csv(input_file, dtype=str)  # Read all columns as strings\n",
    "    timestamps = df.iloc[:, 0].apply(lambda x: datetime.strptime(x.split('Z')[0][:26], \"%Y-%m-%dT%H:%M:%S.%f\").timestamp() * 1000)\n",
    "    min_time, max_time = timestamps.min(), timestamps.max()\n",
    "    df.iloc[:, 0] = timestamps.apply(lambda x: normalize_timestamp(x, min_time, max_time))\n",
    "    df.dropna(subset=[df.columns[0]], inplace=True)  # Remove rows with invalid timestamps\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"\"\n",
    "    output_csv = \"\"\n",
    "    update_csv_timestamps(input_csv, output_csv)\n",
    "    print(f\"Updated CSV saved as {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d99136-7aa2-4c7f-99b9-f6936219c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates 'Device Name' column to replace first two '-' in Device Name\n",
    "\n",
    "import csv\n",
    "\n",
    "def update_device_names(input_csv, output_csv):\n",
    "    with open(input_csv, mode='r', newline='') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        \n",
    "        with open(output_csv, mode='w', newline='') as outfile:\n",
    "            fieldnames = reader.fieldnames\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            \n",
    "            for row in reader:\n",
    "                # Check if 'Device Name' column exists\n",
    "                if 'Device Name' in row:\n",
    "                    device_name = row['Device Name']\n",
    "                    # Replace only the first 2 occurrences of '-'\n",
    "                    device_name = device_name.replace('-', '/', 2)\n",
    "                    row['Device Name'] = device_name\n",
    "                \n",
    "                writer.writerow(row)\n",
    "\n",
    "input_csv = \"\"\n",
    "output_csv = \"\"\n",
    "\n",
    "update_device_names(input_csv, output_csv)\n",
    "print(f\"Updated CSV saved as {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e72c63-c27a-46f7-93d3-8441971a169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the delta between consecutive timestamps in milliseconds\n",
    "def convert_to_time_deltas(df):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "    # Calculate the time difference between each timestamp and the previous one (in seconds)\n",
    "    df['Time (ms)'] = df['Timestamp'].diff().dt.total_seconds() * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the cumulative time in milliseconds (time since the start of the simulation)\n",
    "    df['Cumulative Time (ms)'] = df['Time (ms)'].cumsum()  # Cumulative sum of time differences\n",
    "\n",
    "    # The first row will have 0ms for the start of the simulation...handle the NaN (from diff on the first row)\n",
    "    df['Cumulative Time (ms)'] = df['Cumulative Time (ms)'].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_csv(input_csv, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = convert_to_time_deltas(df)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "input_csv = \"\"\n",
    "output_csv = \"\"\n",
    "\n",
    "process_csv(input_csv, output_csv)\n",
    "print(f\"Updated CSV saved as {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
